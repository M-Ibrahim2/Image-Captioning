# Image Captioning

The Image Captioning project demonstrates the use of a Vision Encoder-Decoder model to automatically generate descriptive captions for images. By combining computer vision and natural language processing techniques, this project enables the generation of textual descriptions that accurately depict the contents of the provided images.

## Key Features

- Integration of a pre-trained Vision Encoder-Decoder model, ViT-GPT2, to generate captions from input images.
- Preprocessing of images using ViTImageProcessor from the transformers library to meet model input requirements.
- Caption generation relies on the model's decoding capabilities to produce descriptive captions for images.
- Customization of generation parameters such as maximum length and number of beams for controlling caption length and diversity.

## Applications

- Content Understanding
- Social Media caption generation
- E-commerce list content generation
- Educational image content generation
